{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise variables and imports\n",
    "import pyroomacoustics.doa as pra\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from room_simulation import Simulation\n",
    "from sine_dataset import SineData\n",
    "from network import SSLConvNet as ConvNet\n",
    "from network import SSLConvNetCosLoss as ConvNetCosLoss\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "MODELS_PATH = \"../models/\"\n",
    "DATA_PATH = \"../thesis_data/\"\n",
    "BATCH_SIZE = 5\n",
    "BATCH_SIZE_MSECOS = 25\n",
    "TEST_SIZE = 10000\n",
    "EPOCHS = int(TEST_SIZE/BATCH_SIZE)\n",
    "EPOCHS_MSECOS = int(TEST_SIZE/BATCH_SIZE_MSECOS)\n",
    "NR_MICS = 2\n",
    "RAD = 50\n",
    "RADII = [50, 500, 5000]\n",
    "ROOM_SIMS = []\n",
    "DATASETS_EXP2 = []\n",
    "MIC_L_DIST = (11, -10)\n",
    "MIC_R_DIST = (11, -10)\n",
    "ABSORPTION = 0.0\n",
    "MIN_FREQ = 20\n",
    "MAX_FREQ = 20000\n",
    "SAMPLE_RATE = int(MAX_FREQ*2.2)\n",
    "TIME = 1\n",
    "MIN_LENGTH = 65000\n",
    "MIN_LENGTH_MSECOS = 48000\n",
    "TO_RAD = np.pi/180\n",
    "TO_DEG = 180/np.pi\n",
    "\n",
    "# Define custom loss function\n",
    "class CosBorderLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CosBorderLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        radial = torch.abs(torch.cos(pred-target) - torch.cos(target-target))\n",
    "        border = nn.functional.relu(pred-2*np.pi) + nn.functional.relu(-pred)\n",
    "        return torch.sum(radial + border)\n",
    "\n",
    "def calcCircumPos(x1, y1, r, theta):\n",
    "    xPositions = x1 + r*torch.sin(theta)\n",
    "    xPositions = r*2-xPositions #Flip x-coordinates\n",
    "    yPositions = y1 + r*(1-torch.cos(theta))\n",
    "    yPositions = r*2-yPositions #Flip y-coordinates\n",
    "    return xPositions, yPositions\n",
    "\n",
    "def calcCircumAngle(cx, cy, x, y):\n",
    "    theta = torch.atan2(cy-y, cx-x)\n",
    "    theta = torch.remainder(torch.remainder(theta, 2*np.pi) + np.pi/2, 2*np.pi)\n",
    "    return theta\n",
    "\n",
    "def computeMeanITD(inL, inR):\n",
    "    non_zero_ind_inL = np.argmax((inL > 0))\n",
    "    non_zero_ind_inR = np.argmax((inR > 0))\n",
    "    \n",
    "    return (non_zero_ind_inL/SAMPLE_RATE - non_zero_ind_inR/SAMPLE_RATE) * 1000\n",
    "\n",
    "def computeMeanIID(inL, inR):\n",
    "    peak_inL_idxs = pra.detect_peaks(inL)\n",
    "    peak_inR_idxs = pra.detect_peaks(inR)\n",
    "\n",
    "    len_diff = len(peak_inL_idxs) - len(peak_inR_idxs)\n",
    "    if len_diff != 0:\n",
    "        if len_diff > 0:\n",
    "            peak_inL_idxs = peak_inL_idxs[len_diff:]\n",
    "        else:\n",
    "            peak_inR_idxs = peak_inR_idxs[abs(len_diff):]\n",
    "    \n",
    "    return np.mean((inL[peak_inL_idxs] - inR[peak_inR_idxs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "500\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "for rad in RADII:\n",
    "    print(rad)\n",
    "    roomSim = Simulation(SAMPLE_RATE, rad, ABSORPTION,MIC_L_DIST, MIC_R_DIST, NR_MICS)\n",
    "    ROOM_SIMS.append(roomSim)\n",
    "\n",
    "    DATASETS_EXP2.append(SineData(BATCH_SIZE, roomSim, TIME, MIN_LENGTH, MIN_FREQ, MAX_FREQ))\n",
    "\n",
    "roomSimMSECos = ROOM_SIMS[0]\n",
    "datasetMSECos = SineData(BATCH_SIZE_MSECOS, roomSimMSECos, TIME, MIN_LENGTH_MSECOS, MIN_FREQ, MAX_FREQ)\n",
    "\n",
    "roomSim = Simulation(SAMPLE_RATE, 50, ABSORPTION,MIC_L_DIST, MIC_R_DIST, NR_MICS)\n",
    "datasetLowFreq = SineData(1, roomSim, TIME, MIN_LENGTH_MSECOS, 20, 1500)\n",
    "datasetMedFreq = SineData(1, roomSim, TIME, MIN_LENGTH_MSECOS, 1500, 3000)\n",
    "datasetHigFreq = SineData(1, roomSim, TIME, MIN_LENGTH_MSECOS, 3000, 20000)\n",
    "DATASETS_EXP3 = [datasetLowFreq, datasetMedFreq, datasetHigFreq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/ConvNet_Rad50'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-159067f0ced8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMIN_LENGTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODELS_PATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"ConvNet_Rad\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../models/ConvNet_Rad50'"
     ]
    }
   ],
   "source": [
    "# Create networks\n",
    "nets = []\n",
    "for rad in RADII:\n",
    "    print(rad)\n",
    "    net = ConvNet(MIN_LENGTH).double()\n",
    "    net.load_state_dict(torch.load(MODELS_PATH+\"ConvNet_Rad\"+str(rad), map_location=\"cpu\"))\n",
    "    net.eval()\n",
    "    nets.append(net)\n",
    "\n",
    "MSENet = ConvNet(MIN_LENGTH_MSECOS).double()\n",
    "MSENet.load_state_dict(torch.load(MODELS_PATH+\"ConvNet_MSELoss\", map_location=\"cpu\"))\n",
    "MSENet.eval()\n",
    "\n",
    "CosNet = ConvNetCosLoss(MIN_LENGTH_MSECOS).double()\n",
    "CosNet.load_state_dict(torch.load(MODELS_PATH+\"ConvNet_CosLoss\", map_location=\"cpu\"))\n",
    "CosNet.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################\n",
    "# EXPERIMENT 1 #\n",
    "################\n",
    "\n",
    "CosLoss = CosBorderLoss()\n",
    "MSELoss = nn.MSELoss()\n",
    "CosLosses = np.zeros((2, EPOCHS_MSECOS))\n",
    "MSELosses = np.zeros((2, EPOCHS_MSECOS))\n",
    "dataLoader = DataLoader(datasetMSECos, batch_size=BATCH_SIZE_MSECOS)\n",
    "\n",
    "for i in range(EPOCHS_MSECOS):\n",
    "    if i%100 == 0:\n",
    "        print(\"Epoch \"+str(i)+\"/\"+str(EPOCHS_MSECOS))\n",
    "    \n",
    "    # Retrieve all input data and labels\n",
    "    inL, inR, labelX, labelY, labelAzi = next(iter(dataLoader))\n",
    "    inL = inL.double().to(device)\n",
    "    inR = inR.double().to(device)\n",
    "    labelX = labelX.double().to(device)\n",
    "    labelY = labelY.double().to(device)\n",
    "    labelAzi = labelAzi.double().to(device)\n",
    "\n",
    "    # Compute MSE and Cos losses for coordinate network\n",
    "    MSENet = MSENet.to(device)\n",
    "    \n",
    "    outputXMSE, outputYMSE = MSENet(inL, inR)\n",
    "    outputXMSE = torch.squeeze(outputXMSE)\n",
    "    outputYMSE = torch.squeeze(outputYMSE)\n",
    "    \n",
    "    outputAziMSE = calcCircumAngle(50, 50, outputXMSE, outputYMSE)\n",
    "    \n",
    "    CosLosses[0,i] = CosLoss(outputAziMSE, labelAzi)\n",
    "    MSELosses[0,i] = MSELoss(outputXMSE, labelX) + MSELoss(outputYMSE, labelY)\n",
    "    \n",
    "     \n",
    "    # Compute MSE and Cos losses for angle network\n",
    "    CosNet = CosNet.to(device)\n",
    "    \n",
    "    outputAziCos = CosNet(inL, inR)\n",
    "    outputAziCos = torch.squeeze(outputAziCos)\n",
    "    outputXCos, outputYCos = calcCircumPos(50, 0, 50, outputAziCos)\n",
    "    \n",
    "    CosLosses[1,i] = CosLoss(outputAziCos, labelAzi)\n",
    "    MSELosses[1,i] = MSELoss(outputXCos, labelX) + MSELoss(outputYCos, labelY)\n",
    "\n",
    "del MSENet, CosNet, inL, inR, labelX, labelY, labelAzi\n",
    "\n",
    "np.save(DATA_PATH+\"exp1_MSE_outcomes\", MSELosses)\n",
    "np.save(DATA_PATH+\"exp1_Cos_outcomes\", CosLosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSELosses_exp1 = np.load(DATA_PATH+\"exp1_MSE_outcomes.npy\")\n",
    "CosLosses_exp1 = np.load(DATA_PATH+\"exp1_Cos_outcomes.npy\")\n",
    "\n",
    "print(\"MSE        COS\")\n",
    "print(\"MSE Losses\")\n",
    "print(np.mean(MSELosses_exp1, axis = 1))\n",
    "print(np.std(MSELosses_exp1, axis = 1))\n",
    "\n",
    "print(\"Cos Losses\")\n",
    "print(np.mean(CosLosses_exp1, axis = 1))\n",
    "print(np.std(CosLosses_exp1, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################\n",
    "# EXPERIMENT 2 #\n",
    "################\n",
    "\n",
    "MSELosses = np.zeros((len(DATASETS_EXP2), len(nets), EPOCHS))\n",
    "\n",
    "for i,dataset in enumerate(DATASETS_EXP2):\n",
    "    print(\"Dataset \"+str(i))\n",
    "\n",
    "    dataLoader = DataLoader(dataset, batch_size = BATCH_SIZE)\n",
    "    \n",
    "    for j,net in enumerate(nets):\n",
    "        print(\"Network \"+str(j))\n",
    "\n",
    "        net.to(device)\n",
    "\n",
    "        for k in range(EPOCHS):\n",
    "            if k%400 == 0:\n",
    "                print(\"Epoch \"+str(k)+\"/\"+str(EPOCHS))\n",
    "            \n",
    "            inL, inR, labelX, labelY, _ = next(iter(dataLoader))\n",
    "            inL = inL.double().to(device)\n",
    "            inR = inR.double().to(device)\n",
    "            labelX = labelX.double().to(device)\n",
    "            labelY = labelY.double().to(device)\n",
    "\n",
    "            outputX, outputY = net(inL, inR)\n",
    "            outputX = torch.squeeze(outputX)\n",
    "            outputY = torch.squeeze(outputY)\n",
    "\n",
    "            MSELosses[i,j,k] = MSELoss(outputX, labelX) + MSELoss(outputY, labelY)\n",
    "\n",
    "        del net, inL, inR, labelX, labelY\n",
    "\n",
    "np.save(DATA_PATH+\"exp2_outcomes\", MSELosses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses_exp2 = np.load(DATA_PATH+\"exp2_outcomes.npy\")\n",
    "\n",
    "print(\"50    500    5000\")\n",
    "print(\"RAD = 50\")\n",
    "print(np.mean(losses_exp2[0], axis=1))\n",
    "print(np.std(losses_exp2[0], axis=1))\n",
    "print(\"RAD = 500\")\n",
    "print(np.mean(losses_exp2[1], axis=1))\n",
    "print(np.std(losses_exp2[1], axis=1))\n",
    "print(\"RAD = 5000\")\n",
    "print(np.mean(losses_exp2[2], axis=1))\n",
    "print(np.std(losses_exp2[2], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "################\n",
    "# EXPERIMENT 3 #\n",
    "################\n",
    "\n",
    "BATCH_SIZE_EXP3 = 1\n",
    "TEST_SIZE_EXP3 = 1500\n",
    "EPOCHS_EXP3 = int(TEST_SIZE_EXP3/BATCH_SIZE_EXP3)\n",
    "ITDs = np.zeros((len(DATASETS_EXP3), EPOCHS_EXP3))\n",
    "IIDs = np.zeros((len(DATASETS_EXP3), EPOCHS_EXP3))\n",
    "threshold = 2e-12\n",
    "MSENet = ConvNet(MIN_LENGTH_MSECOS).double()\n",
    "MSENet.load_state_dict(torch.load(MODELS_PATH+\"ConvNet_MSELoss\", map_location=\"cpu\"))\n",
    "MSENet.eval()\n",
    "MSENet = MSENet.to(device)\n",
    "\n",
    "for i,dataset in enumerate(DATASETS_EXP3):\n",
    "    \n",
    "    print(\"Dataset \"+str(i))\n",
    "    dataLoader = DataLoader(dataset, batch_size = BATCH_SIZE_EXP3)\n",
    "    \n",
    "    for j in range(EPOCHS_EXP3):\n",
    "        \n",
    "        ITDs_batch = []\n",
    "        IIDs_batch = []\n",
    "        \n",
    "        if j%100 == 0:\n",
    "                print(\"Epoch \"+str(j)+\"/\"+str(EPOCHS_EXP3))\n",
    "                \n",
    "        inLs, inRs, _, _, _ = next(iter(dataLoader))\n",
    "        \n",
    "        for signalIdx in range(inLs.size(0)):\n",
    "            inL = inLs[signalIdx].numpy()\n",
    "            inR = inRs[signalIdx].numpy()\n",
    "\n",
    "            inL[np.where(np.abs(inL) < threshold)] = 0\n",
    "            inR[np.where(np.abs(inR) < threshold)] = 0\n",
    "\n",
    "            ITDs_batch.append(computeMeanITD(inL, inR))\n",
    "            IIDs_batch.append(computeMeanIID(inL, inR))\n",
    "        \n",
    "        ITDs[i,j] = np.mean(ITDs_batch)\n",
    "        IIDs[i,j] = np.mean(IIDs_batch)\n",
    "        \n",
    "        inLs = inLs.double().to(device)\n",
    "        inRs = inRs.double().to(device)\n",
    "        _, _ = MSENet(inLs, inRs, record_acts = True)\n",
    "        \n",
    "        del inLs, inRs\n",
    "\n",
    "del net        \n",
    "        \n",
    "import scipy.stats\n",
    "\n",
    "np.save(DATA_PATH+\"exp3_ITDs.npy\", ITDs)\n",
    "np.save(DATA_PATH+\"exp3_IIDs.npy\", IIDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITDs = np.load(DATA_PATH+\"exp3_ITDs.npy\")\n",
    "IIDs = np.load(DATA_PATH+\"exp3_IIDs.npy\")\n",
    "\n",
    "for i,freq in enumerate([\"LowFreq\",\"MedFreq\",\"HigFreq\"]):\n",
    "    print(freq+\" ITD correlation = \" + str(scipy.stats.pearsonr(MSENet.fc_activations[1500*i:1500*(i+1)], ITDs[i])))\n",
    "    print(freq+\" IID correlation = \" + str(scipy.stats.pearsonr(MSENet.fc_activations[1500*i:1500*(i+1)], IIDs[i])))\n",
    "\n",
    "print(np.min(ITDs, axis=1))\n",
    "print(np.max(ITDs, axis=1))\n",
    "\n",
    "print(np.min(IIDs, axis=1))\n",
    "print(np.max(IIDs, axis=1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
